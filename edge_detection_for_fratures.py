# -*- coding: utf-8 -*-
"""MV3 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sxt8tU5J8XLCTXjA6W0OaLad7tBhWEuA

# Libraries
"""

# Core
import kagglehub
import os
import random
import yaml
import numpy as np
import cv2

# Visualization
import matplotlib.pyplot as plt
from PIL import Image
import matplotlib.patches as patches

"""# Load and save"""

# Download dataset
root_dir = kagglehub.dataset_download("orvile/human-bone-fractures-image-dataset-hbfmid")
print("Path to dataset files:", root_dir)

for root, dirs, files in os.walk(root_dir):
    # Indentation level
    level = root.replace(root_dir, "").count(os.sep)
    indent = "  " * level

    # Print folder names
    print(f"{indent}{os.path.basename(root)}/")

yaml_path = os.path.join(root_dir,
                        "Human Bone Fractures Multi-modal Image Dataset (HBFMID)",
                        "Bone Fractures Detection",
                        "data.yaml")

print("YAML:", yaml_path)

with open(yaml_path, "r") as f:
    data = yaml.safe_load(f)

print(data)

# Flatten and print YAML content simply
print("train:", data["train"])
print("val:", data["val"])
print("test:", data["test"])

# Number of classes
print("\nnc:", data["nc"])

# Labels
print("\nnames:")
for i, name in enumerate(data["names"]):
    print(f"  {i}: {name}")

# Source and background of this project
print("\nroboflow:")
for k, v in data["roboflow"].items():
    print(f"  {k}: {v}")

"""# Preprocessing

## Sample images
"""

# Sample images
train_images_dir = os.path.join(
    root_dir,
    "Human Bone Fractures Multi-modal Image Dataset (HBFMID)",
    "Bone Fractures Detection",
    "train",
    "images"
)

# Get list of image files
image_files = [f for f in os.listdir(train_images_dir)
               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

# Pick 25 random images
sample_files = random.sample(image_files, min(25, len(image_files)))

plt.figure(figsize=(20,12))

for i, img_name in enumerate(sample_files, 1):
    img_path = os.path.join(train_images_dir, img_name)
    img = Image.open(img_path)
    plt.subplot(5,5,i)
    plt.imshow(img)
    plt.axis('off')

plt.tight_layout()
plt.show()

"""## Sample images with YOLO bounding boxes"""

# Sample images with bounding boxes
train_labels_dir = os.path.join(
    root_dir,
    "Human Bone Fractures Multi-modal Image Dataset (HBFMID)",
    "Bone Fractures Detection",
    "train",
    "labels")

# Get image files
image_files = [f for f in os.listdir(train_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

# Random sample
sample_files = random.sample(image_files, min(15, len(image_files)))

plt.figure(figsize=(15, 10))

for i, img_name in enumerate(sample_files, 1):
    img_path = os.path.join(train_images_dir, img_name)
    label_path = os.path.join(train_labels_dir, img_name.rsplit('.', 1)[0] + ".txt")

    # Open image
    img = Image.open(img_path)
    w, h = img.size  # image width, height

    # Create plot
    ax = plt.subplot(3, 5, i)
    ax.imshow(img)

    # Draw bounding boxes if label file exists
    if os.path.exists(label_path):
        with open(label_path, "r") as f:
            for idx, line in enumerate(f):
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id, x_center, y_center, box_width, box_height = map(float, parts)

                    # Convert from YOLO format to pixel coordinates
                    x_center *= w
                    y_center *= h
                    box_width *= w
                    box_height *= h

                    x_min = x_center - box_width / 2
                    y_min = y_center - box_height / 2

                    # Create rectangle
                    rect = patches.Rectangle(
                        (x_min, y_min), box_width, box_height,
                        linewidth=2, edgecolor='red', facecolor='none'
                    )
                    ax.add_patch(rect)
                    ax.text(x_min,
                            y_min - 5 - (12 * idx),
                            f"Class {int(class_id)} - {data['names'][int(class_id)]}",
                            color='red',
                            fontsize=8,
                            backgroundcolor='white'                        )

    ax.axis('off')

plt.tight_layout()
plt.show()

"""# MV

## Select images
"""

# Dataset base path
base_dir = os.path.join(
    root_dir,
    "Human Bone Fractures Multi-modal Image Dataset (HBFMID)",
    "Bone Fractures Detection")

# Define image + label paths
train_images = os.path.join(base_dir, "train", "images")
train_labels = os.path.join(base_dir, "train", "labels")

val_images = os.path.join(base_dir, "valid", "images")
val_labels = os.path.join(base_dir, "valid", "labels")

test_images = os.path.join(base_dir, "test", "images")
test_labels = os.path.join(base_dir, "test", "labels")

# Use these for selection:
images_dir = train_images
labels_dir = train_labels

print("Using images_dir:", images_dir)
print("Using labels_dir:", labels_dir)

# -------------------------------------------------------------
# STEP 1 — Select 1 IMAGE PER CLASS
# -------------------------------------------------------------

print("\n===== STEP 1: LOADING IMAGES =====")

RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

class_names = data["names"]
num_classes = data["nc"]

# Map images to their class using YOLO labels
image_class_map = {i: [] for i in range(num_classes)}

for img_file in os.listdir(images_dir):
    if not img_file.lower().endswith((".png", ".jpg", ".jpeg")):
        continue

    label_file = img_file.rsplit(".", 1)[0] + ".txt"
    label_path = os.path.join(labels_dir, label_file)

    if os.path.exists(label_path):
        with open(label_path, "r") as f:
            line = f.readline().strip().split()
            if len(line) >= 1:
                class_id = int(line[0])
                image_class_map[class_id].append(img_file)

# Sort for deterministic selection
for cls in image_class_map:
    image_class_map[cls] = sorted(image_class_map[cls])

# Choose 1 image per class
selected_images = {}
for cls, files in image_class_map.items():
    if len(files) > 0:
        selected_images[cls] = random.sample(files, 1)[0]

print("\nSelected images per class:")
for cls, img_name in selected_images.items():
    print(f"  Class {cls} ({class_names[cls]}): {img_name}")

# Load images into memory (BGR)
loaded_images = {}
for cls, img_name in selected_images.items():
    img_path = os.path.join(images_dir, img_name)
    img_bgr = cv2.imread(img_path)
    loaded_images[cls] = img_bgr

print("\n===== STEP 1 COMPLETE =====")

"""## Convert to grayscale, compute histogram & CDF"""

# -------------------------------------------------------------
# STEP 2 — CONVERT TO GRAYSCALE + COMPUTE HISTOGRAM & CDF
# -------------------------------------------------------------

print("\n===== STEP 2: GRAYSCALE + HISTOGRAM + CDF =====")

gray_images = {}
histograms = {}
cdfs = {}

for cls, img_bgr in loaded_images.items():

    if img_bgr is None:
        print(f"[ERROR] Could not load image for class {cls}. Skipping.")
        continue

    # Convert to grayscale
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    gray_images[cls] = gray

    # Compute histogram
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256]).flatten()
    histograms[cls] = hist

    # Compute CDF
    cdf = hist.cumsum()
    cdf = cdf / cdf[-1]  # normalize to 1
    cdfs[cls] = cdf

print("\nGrayscale images, histograms, and CDFs computed.")
print("===== STEP 2 COMPLETE =====")

"""## Visualization after grayscale"""

# -------------------------------------------------------------
# STEP 3 — VISUALIZATION: N × 3 MATRIX (TRANSPOSED)
# -------------------------------------------------------------

print("\n===== STEP 3: VISUALIZATION (N × 3 TRANSPOSED) =====")

num_classes_to_plot = len(selected_images)
plt.figure(figsize=(14, 3 * num_classes_to_plot))  # Taller figure for rows

for row_index, cls in enumerate(selected_images):

    # ---------------------
    # Column 1: Original RGB
    # ---------------------
    plt.subplot(num_classes_to_plot, 3, row_index * 3 + 1)
    rgb = cv2.cvtColor(loaded_images[cls], cv2.COLOR_BGR2RGB)
    plt.imshow(rgb)
    plt.title(f"Class {cls}\n{class_names[cls]}")
    plt.axis("off")

    # ---------------------
    # Column 2: Grayscale
    # ---------------------
    plt.subplot(num_classes_to_plot, 3, row_index * 3 + 2)
    plt.imshow(gray_images[cls], cmap="gray")
    plt.title("Grayscale")
    plt.axis("off")

    # ---------------------
    # Column 3: Histogram + CDF
    # ---------------------
    plt.subplot(num_classes_to_plot, 3, row_index * 3 + 3)
    hist = histograms[cls]
    cdf = cdfs[cls]

    plt.bar(np.arange(256), hist, color="gray", alpha=0.7, label="Histogram")
    plt.plot(cdf * hist.max(), color="red", linewidth=2, label="CDF")
    plt.xlim([0, 255])
    plt.title("Histogram + CDF")
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

plt.tight_layout()
plt.show()

print("\n===== STEP 3 COMPLETE (TRANSPOSED) =====")

"""## Histogram equalization

### Global HE computation
"""

# -------------------------------------------------------------
# GLOBAL HISTOGRAM EQUALIZATION — COMPUTE
# -------------------------------------------------------------

print("\n===== GLOBAL HISTOGRAM EQUALIZATION: COMPUTE =====")

equalized_global = {}
hist_global = {}
cdf_global = {}

for cls, gray in gray_images.items():
    # Apply global histogram equalization
    g_eq = cv2.equalizeHist(gray)
    equalized_global[cls] = g_eq

    # Histogram
    hist_g = cv2.calcHist([g_eq], [0], None, [256], [0, 256]).flatten()
    hist_global[cls] = hist_g

    # CDF
    cdf_g = hist_g.cumsum()
    cdf_g = cdf_g / cdf_g[-1]
    cdf_global[cls] = cdf_g

print("Global histogram equalization (image, hist, CDF) computed for all classes.")
print("===== DONE =====")

"""### Global HE visualization"""

# -------------------------------------------------------------
# GLOBAL HISTOGRAM EQUALIZATION — VISUALIZE
# -------------------------------------------------------------

print("\n===== GLOBAL HISTOGRAM EQUALIZATION: VISUALIZATION =====")

num_classes_to_plot = len(selected_images)
plt.figure(figsize=(22, 4 * num_classes_to_plot))

for row_index, cls in enumerate(selected_images):

    # 1) Grayscale before
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 1)
    plt.imshow(gray_images[cls], cmap="gray")
    plt.title(f"Class {cls} {class_names[cls]}\nGrayscale")
    plt.axis("off")

    # 2) Original histogram + CDF
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 2)
    hist = histograms[cls]
    cdf  = cdfs[cls]
    plt.bar(np.arange(256), hist, color="gray", alpha=0.7, label="Histogram")
    plt.plot(cdf * hist.max(), color="red", linewidth=2, label="CDF")
    plt.title("Original Hist + CDF")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

    # 3) Globally equalized image
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 3)
    plt.imshow(equalized_global[cls], cmap="gray")
    plt.title("Globally Equalized")
    plt.axis("off")

    # 4) Equalized histogram + CDF
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 4)
    hist_g = hist_global[cls]
    cdf_g  = cdf_global[cls]
    plt.bar(np.arange(256), hist_g, color="gray", alpha=0.7, label="Histogram")
    plt.plot(cdf_g * hist_g.max(), color="red", linewidth=2, label="CDF")
    plt.title("Equalized Hist + CDF")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

plt.tight_layout()
plt.show()

print("\n===== GLOBAL HISTEQ VISUALIZATION DONE =====")

"""### Contrast Limited Adaptive Histogram Equalization (CLAHE) computation"""

# -------------------------------------------------------------
# CLAHE — COMPUTE
# -------------------------------------------------------------

print("\n===== CLAHE: COMPUTE =====")

equalized_clahe = {}
hist_clahe = {}
cdf_clahe = {}

clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

for cls, gray in gray_images.items():
    # Apply CLAHE
    c_eq = clahe.apply(gray)
    equalized_clahe[cls] = c_eq

    # Histogram
    hist_c = cv2.calcHist([c_eq], [0], None, [256], [0, 256]).flatten()
    hist_clahe[cls] = hist_c

    # CDF
    cdf_c = hist_c.cumsum()
    cdf_c = cdf_c / cdf_c[-1]
    cdf_clahe[cls] = cdf_c

print("CLAHE (image, hist, CDF) computed for all classes.")
print("===== DONE =====")

"""### Contrast Limited Adaptive Histogram Equalization (CLAHE) visualization"""

# -------------------------------------------------------------
# CLAHE — VISUALIZE
# -------------------------------------------------------------

print("\n===== CLAHE: VISUALIZATION =====")

num_classes_to_plot = len(selected_images)
plt.figure(figsize=(22, 4 * num_classes_to_plot))

for row_index, cls in enumerate(selected_images):

    # 1) Grayscale before
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 1)
    plt.imshow(gray_images[cls], cmap="gray")
    plt.title(f"Class {cls} {class_names[cls]}\nGrayscale")
    plt.axis("off")

    # 2) Original histogram + CDF
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 2)
    hist = histograms[cls]
    cdf  = cdfs[cls]
    plt.bar(np.arange(256), hist, color="gray", alpha=0.7, label="Histogram")
    plt.plot(cdf * hist.max(), color="red", linewidth=2, label="CDF")
    plt.title("Original Hist + CDF")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

    # 3) CLAHE image
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 3)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title("CLAHE Equalized")
    plt.axis("off")

    # 4) CLAHE histogram + CDF
    plt.subplot(num_classes_to_plot, 4, row_index * 4 + 4)
    hist_c = hist_clahe[cls]
    cdf_c  = cdf_clahe[cls]
    plt.bar(np.arange(256), hist_c, color="gray", alpha=0.7, label="Histogram")
    plt.plot(cdf_c * hist_c.max(), color="red", linewidth=2, label="CDF")
    plt.title("CLAHE Hist + CDF")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

plt.tight_layout()
plt.show()

print("\n===== CLAHE VISUALIZATION DONE =====")

"""### Histogram comparison"""

# -------------------------------------------------------------
# STEP 5 — N × 3 HISTOGRAM + CDF MATRIX
# Col 1: Original  | Col 2: Global EQ | Col 3: CLAHE
# -------------------------------------------------------------

print("\n===== STEP 5: N × 3 HISTOGRAM + CDF MATRIX =====")

num_classes = len(selected_images)
plt.figure(figsize=(18, 4 * num_classes))

for row_index, cls in enumerate(selected_images):

    # ---------------------------------------
    # Column 1 — Original Histogram + CDF
    # ---------------------------------------
    plt.subplot(num_classes, 3, row_index * 3 + 1)
    hist_o = histograms[cls]
    cdf_o  = cdfs[cls]

    plt.bar(np.arange(256), hist_o, color="gray", alpha=0.7, label="Hist")
    plt.plot(cdf_o * hist_o.max(), color="red", linewidth=2, label="CDF")
    plt.title(f"Class {cls}: {class_names[cls]}\nOriginal")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

    # ---------------------------------------
    # Column 2 — Global Equalized Histogram + CDF
    # ---------------------------------------
    plt.subplot(num_classes, 3, row_index * 3 + 2)
    hist_g = hist_global[cls]
    cdf_g  = cdf_global[cls]

    plt.bar(np.arange(256), hist_g, color="blue", alpha=0.7, label="Hist")
    plt.plot(cdf_g * hist_g.max(), color="red", linewidth=2, label="CDF")
    plt.title("Global Equalized")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

    # ---------------------------------------
    # Column 3 — CLAHE Histogram + CDF
    # ---------------------------------------
    plt.subplot(num_classes, 3, row_index * 3 + 3)
    hist_c = hist_clahe[cls]
    cdf_c  = cdf_clahe[cls]

    plt.bar(np.arange(256), hist_c, color="green", alpha=0.7, label="Hist")
    plt.plot(cdf_c * hist_c.max(), color="red", linewidth=2, label="CDF")
    plt.title("CLAHE")
    plt.xlim([0, 255])
    plt.xlabel("Intensity")
    plt.ylabel("Count")
    plt.legend(fontsize=7)

plt.tight_layout()
plt.show()

print("\n===== HISTOGRAM + CDF MATRIX COMPLETE =====")

"""## Filtering & Edge detection

### Gaussian filter
"""

# -------------------------------------------------------------
# STEP X — GAUSSIAN SMOOTHING WITH 3×3, 5×5, 9×9 (ON CLAHE)
# -------------------------------------------------------------

print("\n===== GAUSSIAN SMOOTHING (CLAHE INPUT) =====")

gauss_3 = {}
gauss_5 = {}
gauss_9 = {}

for cls, img in equalized_clahe.items():
    # Gaussian kernels must be odd numbers, as required by OpenCV
    gauss_3[cls] = cv2.GaussianBlur(img, (3, 3), 0)
    gauss_5[cls] = cv2.GaussianBlur(img, (5, 5), 0)
    gauss_9[cls] = cv2.GaussianBlur(img, (9, 9), 0)

print("Gaussian smoothing completed for kernel sizes 3×3, 5×5, and 9×9.")

# -------------------------------------------------------------
# GAUSSIAN VISUALIZATION — N × 4 MATRIX
# -------------------------------------------------------------

num_classes = len(selected_images)
plt.figure(figsize=(20, 4 * num_classes))

for row_index, cls in enumerate(selected_images):

    # Column 1: CLAHE image
    plt.subplot(num_classes, 4, row_index * 4 + 1)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title(f"Class {cls}: {class_names[cls]}\nCLAHE")
    plt.axis("off")

    # Column 2: Gaussian 3×3
    plt.subplot(num_classes, 4, row_index * 4 + 2)
    plt.imshow(gauss_3[cls], cmap="gray")
    plt.title("Gaussian 3×3")
    plt.axis("off")

    # Column 3: Gaussian 5×5
    plt.subplot(num_classes, 4, row_index * 4 + 3)
    plt.imshow(gauss_5[cls], cmap="gray")
    plt.title("Gaussian 5×5")
    plt.axis("off")

    # Column 4: Gaussian 9×9
    plt.subplot(num_classes, 4, row_index * 4 + 4)
    plt.imshow(gauss_9[cls], cmap="gray")
    plt.title("Gaussian 9×9")
    plt.axis("off")

plt.tight_layout()
plt.show()

print("\n===== GAUSSIAN SMOOTHING VISUALIZATION COMPLETE =====")

"""### Median filtering"""

# -------------------------------------------------------------
# STEP X — MEDIAN FILTERING WITH 3×3, 5×5, 7×7 (ON CLAHE)
# -------------------------------------------------------------

print("\n===== MEDIAN FILTERING (CLAHE INPUT) =====")

median_3 = {}
median_5 = {}
median_7 = {}

for cls, img in equalized_clahe.items():
    median_3[cls] = cv2.medianBlur(img, 3)
    median_5[cls] = cv2.medianBlur(img, 5)
    median_7[cls] = cv2.medianBlur(img, 7)

print("Median filtering completed for kernel sizes 3×3, 5×5, and 7×7.")

# -------------------------------------------------------------
# MEDIAN FILTERING VISUALIZATION — N × 4 MATRIX
# -------------------------------------------------------------

num_classes = len(selected_images)
plt.figure(figsize=(20, 4 * num_classes))

for row_index, cls in enumerate(selected_images):

    # Column 1: CLAHE image
    plt.subplot(num_classes, 4, row_index * 4 + 1)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title(f"Class {cls}: {class_names[cls]}\nCLAHE")
    plt.axis("off")

    # Column 2: Median 3×3
    plt.subplot(num_classes, 4, row_index * 4 + 2)
    plt.imshow(median_3[cls], cmap="gray")
    plt.title("Median 3×3")
    plt.axis("off")

    # Column 3: Median 5×5
    plt.subplot(num_classes, 4, row_index * 4 + 3)
    plt.imshow(median_5[cls], cmap="gray")
    plt.title("Median 5×5")
    plt.axis("off")

    # Column 4: Median 7×7
    plt.subplot(num_classes, 4, row_index * 4 + 4)
    plt.imshow(median_7[cls], cmap="gray")
    plt.title("Median 7×7")
    plt.axis("off")

plt.tight_layout()
plt.show()

print("\n===== MEDIAN FILTERING VISUALIZATION COMPLETE =====")

"""### Bilateral filtering"""

# -------------------------------------------------------------
# STEP X — BILATERAL FILTERING (THREE LEVELS)
# -------------------------------------------------------------

print("\n===== BILATERAL FILTERING (CLAHE INPUT) =====")

bilat_light = {}
bilat_med   = {}
bilat_strong = {}

for cls, img in equalized_clahe.items():

    # Light smoothing
    bilat_light[cls] = cv2.bilateralFilter(img, d=5, sigmaColor=25, sigmaSpace=25)

    # Medium smoothing
    bilat_med[cls]   = cv2.bilateralFilter(img, d=7, sigmaColor=50, sigmaSpace=50)

    # Strong smoothing
    bilat_strong[cls] = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)

print("Bilateral filtering completed at light, medium, and strong levels.")

# -------------------------------------------------------------
# BILATERAL FILTERING VISUALIZATION — N × 4 MATRIX
# -------------------------------------------------------------

num_classes = len(selected_images)
plt.figure(figsize=(20, 4 * num_classes))

for row_index, cls in enumerate(selected_images):

    # Column 1: CLAHE image
    plt.subplot(num_classes, 4, row_index * 4 + 1)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title(f"Class {cls}: {class_names[cls]}\nCLAHE")
    plt.axis("off")

    # Column 2: Bilateral (Light)
    plt.subplot(num_classes, 4, row_index * 4 + 2)
    plt.imshow(bilat_light[cls], cmap="gray")
    plt.title("Bilateral (Light)")
    plt.axis("off")

    # Column 3: Bilateral (Medium)
    plt.subplot(num_classes, 4, row_index * 4 + 3)
    plt.imshow(bilat_med[cls], cmap="gray")
    plt.title("Bilateral (Medium)")
    plt.axis("off")

    # Column 4: Bilateral (Strong)
    plt.subplot(num_classes, 4, row_index * 4 + 4)
    plt.imshow(bilat_strong[cls], cmap="gray")
    plt.title("Bilateral (Strong)")
    plt.axis("off")

plt.tight_layout()
plt.show()

print("\n===== BILATERAL FILTERING VISUALIZATION COMPLETE =====")

"""### Laplacian"""

# -------------------------------------------------------------
# STEP X — LAPLACIAN EDGE ENHANCEMENT (WEAK, STRONG, VERY STRONG)
# -------------------------------------------------------------

print("\n===== LAPLACIAN FILTERING (CLAHE INPUT) =====")

laplace_weak = {}
laplace_strong = {}
laplace_very_strong = {}

kernel_weak = np.array([[0, -1, 0],
                        [-1, 4, -1],
                        [0, -1, 0]], dtype=np.float32)

kernel_strong = np.array([[-1, -1, -1],
                          [-1,  8, -1],
                          [-1, -1, -1]], dtype=np.float32)

# Very strong Laplacian kernel (more aggressive)
kernel_very_strong = np.array([[1, 1, 1],
                               [1, -8, 1],
                               [1, 1, 1]], dtype=np.float32)

for cls, img in equalized_clahe.items():

    img_float = img.astype(np.float32)

    # Weak Laplacian
    lap_w = cv2.filter2D(img_float, -1, kernel_weak)
    laplace_weak[cls] = cv2.convertScaleAbs(lap_w)

    # Strong Laplacian
    lap_s = cv2.filter2D(img_float, -1, kernel_strong)
    laplace_strong[cls] = cv2.convertScaleAbs(lap_s)

    # Very Strong Laplacian
    lap_vs = cv2.filter2D(img_float, -1, kernel_very_strong)
    laplace_very_strong[cls] = cv2.convertScaleAbs(lap_vs)

print("Laplacian (weak, strong, very strong) computed for all classes.")

# -------------------------------------------------------------
# LAPLACIAN VISUALIZATION — N × 4 MATRIX (WITH VERY STRONG)
# -------------------------------------------------------------

num_classes = len(selected_images)
plt.figure(figsize=(22, 4 * num_classes))

for row_index, cls in enumerate(selected_images):

    # Column 1 — CLAHE
    plt.subplot(num_classes, 4, row_index * 4 + 1)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title(f"Class {cls}: {class_names[cls]}\nCLAHE")
    plt.axis("off")

    # Column 2 — Weak Laplacian
    plt.subplot(num_classes, 4, row_index * 4 + 2)
    plt.imshow(laplace_weak[cls], cmap="gray")
    plt.title("Laplacian (Weak)")
    plt.axis("off")

    # Column 3 — Strong Laplacian
    plt.subplot(num_classes, 4, row_index * 4 + 3)
    plt.imshow(laplace_strong[cls], cmap="gray")
    plt.title("Laplacian (Strong)")
    plt.axis("off")

    # Column 4 — Very Strong Laplacian
    plt.subplot(num_classes, 4, row_index * 4 + 4)
    plt.imshow(laplace_very_strong[cls], cmap="gray")
    plt.title("Laplacian (Very Strong)")
    plt.axis("off")

plt.tight_layout()
plt.show()

print("\n===== LAPLACIAN VISUALIZATION COMPLETE =====")

"""### Unsharp masking"""

# -------------------------------------------------------------
# STEP X — UNSHARP MASKING: LIGHT, MEDIUM, STRONG
# -------------------------------------------------------------

print("\n===== UNSHARP MASKING (LIGHT, MEDIUM, STRONG) =====")

unsharp_light = {}
unsharp_medium = {}
unsharp_strong = {}

alpha_light = 1.0
alpha_med   = 2.0
alpha_strong = 3.0

for cls, img in equalized_clahe.items():

    img_float = img.astype(np.float32)

    # Gaussian blur for base low-frequency component
    blurred = cv2.GaussianBlur(img_float, (5, 5), 0)

    # High-frequency component
    mask = img_float - blurred

    # Light sharpening
    sharp_l = img_float + alpha_light * mask
    unsharp_light[cls] = cv2.convertScaleAbs(sharp_l)

    # Medium sharpening
    sharp_m = img_float + alpha_med * mask
    unsharp_medium[cls] = cv2.convertScaleAbs(sharp_m)

    # Strong sharpening
    sharp_s = img_float + alpha_strong * mask
    unsharp_strong[cls] = cv2.convertScaleAbs(sharp_s)

print("Unsharp masking completed for all three levels.")

# -------------------------------------------------------------
# UNSHARP MASKING VISUALIZATION — N × 4 MATRIX
# -------------------------------------------------------------

num_classes = len(selected_images)
plt.figure(figsize=(20, 4 * num_classes))

for row_index, cls in enumerate(selected_images):

    # Column 1 — CLAHE image
    plt.subplot(num_classes, 4, row_index * 4 + 1)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title(f"Class {cls}: {class_names[cls]}\nCLAHE")
    plt.axis("off")

    # Column 2 — Unsharp Light
    plt.subplot(num_classes, 4, row_index * 4 + 2)
    plt.imshow(unsharp_light[cls], cmap="gray")
    plt.title("Unsharp (Light, α=1)")
    plt.axis("off")

    # Column 3 — Unsharp Medium
    plt.subplot(num_classes, 4, row_index * 4 + 3)
    plt.imshow(unsharp_medium[cls], cmap="gray")
    plt.title("Unsharp (Medium, α=2)")
    plt.axis("off")

    # Column 4 — Unsharp Strong
    plt.subplot(num_classes, 4, row_index * 4 + 4)
    plt.imshow(unsharp_strong[cls], cmap="gray")
    plt.title("Unsharp (Strong, α=3)")
    plt.axis("off")

plt.tight_layout()
plt.show()

print("\n===== UNSHARP MASKING VISUALIZATION COMPLETE =====")

"""### Filter comparison

# Sobel Edge Strength Definition

Sobel edge strength measures how sharp an image is.
It quantifies the average intensity of edges by detecting how quickly pixel values change in both the horizontal and vertical directions.

### What it represents:
- The clarity of bone boundaries
- The visibility of fracture lines
- The overall sharpness and contrast transitions in the image

### Interpretation:
- **High Sobel edge strength** → The image has strong, clear edges.
  Filters that increase this metric help make fracture lines more visible.
- **Low Sobel edge strength** → The image is smoother, and edges are weaker.
  Strong smoothing filters reduce this metric.

In short:
**Sobel edge strength tells you how much edge information is present in the image.**



# Residual Noise Standard Deviation Definition

Residual noise measures how much a filter has altered the original image.
It compares the filtered image to a baseline version (here, the CLAHE image) and quantifies the variability of the differences.

### What it represents:
- How much detail was changed or lost
- How much noise was introduced
- How strongly the filter modified fine structures

### Interpretation:
- **Low residual noise** →
  The filtered image is very similar to the baseline.
  Good for preserving anatomical detail.

- **High residual noise** →
  The filter introduced significant changes, either through:
  - smoothing (blurring),
  - sharpening, or
  - amplifying noise.

In short:
**Residual noise tells you how much the filter modified the image.**



# Combined Meaning

Together, the two metrics describe filter quality:

- Sobel edge strength → *How sharp are the edges?*
- Residual noise → *How much unwanted alteration happened?*

A good filter increases edge strength while keeping noise low.
"""

# -------------------------------------------------------------
# STEP X — COMPARE ALL FILTERING METHODS (SORTED, NO CLAHE)
# -------------------------------------------------------------

print("\n===== FILTER QUALITY COMPARISON (SORTED, CLAHE EXCLUDED) =====")

def sobel_edge_strength(image):
    gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)
    mag = np.sqrt(gx**2 + gy**2)
    return np.mean(mag)

def residual_std(base, filtered):
    diff = filtered.astype(np.float32) - base.astype(np.float32)
    return np.std(diff)

# Remove CLAHE from comparison
filters_no_clahe = {
    "Gauss_3x3": gauss_3,
    "Gauss_5x5": gauss_5,
    "Gauss_9x9": gauss_9,

    "Median_3x3": median_3,
    "Median_5x5": median_5,
    "Median_7x7": median_7,

    "Bilateral_Light": bilat_light,
    "Bilateral_Medium": bilat_med,
    "Bilateral_Strong": bilat_strong,

    "Laplace_Weak": laplace_weak,
    "Laplace_Strong": laplace_strong,
    "Laplace_VeryStrong": laplace_very_strong,

    "Unsharp_Light": unsharp_light,
    "Unsharp_Medium": unsharp_medium,
    "Unsharp_Strong": unsharp_strong,
}

eps = 1e-6  # prevent division by zero

for cls in selected_images:

    print(f"\n===== Class {cls}: {class_names[cls]} =====")
    print(f"{'Filter':20s} | {'EdgeStr':>10s} | {'NoiseStd':>10s} | {'Score':>10s}")
    print("-" * 65)

    clahe_img = equalized_clahe[cls]

    rows = []
    for name, fmap in filters_no_clahe.items():
        img = fmap[cls]

        E = sobel_edge_strength(img)
        N = residual_std(clahe_img, img)
        score = E / (N + eps)

        rows.append((name, E, N, score))

    # Sort best to worst by score
    rows_sorted = sorted(rows, key=lambda x: x[3], reverse=True)

    # Print sorted results
    for name, E, N, score in rows_sorted:
        print(f"{name:20s} | {E:10.4f} | {N:10.4f} | {score:10.4f}")

print("\n===== SORTED FILTER COMPARISON COMPLETE =====")

"""## Edge detection

### Sobel Edge Detector
"""

# -------------------------------------------------------------
# STEP X — SOBEL ON CLAHE AND BEST FILTER PER CLASS
# -------------------------------------------------------------

# Best filter per class based on your score table
best_filters = {
    0: "Bilateral_Light",
    1: "Unsharp_Light",
    2: "Median_3x3",
    3: "Unsharp_Light",
    4: "Median_3x3",
    5: "Unsharp_Light",
    6: "Bilateral_Light",
    7: "Unsharp_Light",
    8: "Unsharp_Light",
    9: "Bilateral_Light",
}

# Mapping filter names to filter dictionaries
filter_dict = {
    "Gauss_3x3": gauss_3,
    "Gauss_5x5": gauss_5,
    "Gauss_9x9": gauss_9,
    "Median_3x3": median_3,
    "Median_5x5": median_5,
    "Median_7x7": median_7,
    "Bilateral_Light": bilat_light,
    "Bilateral_Medium": bilat_med,
    "Bilateral_Strong": bilat_strong,
    "Unsharp_Light": unsharp_light,
    "Unsharp_Medium": unsharp_medium,
    "Unsharp_Strong": unsharp_strong,}

def sobel_edges(img):
    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)
    mag = np.sqrt(gx**2 + gy**2)
    mag = (mag / mag.max() * 255).astype(np.uint8)
    return mag

# Produce one figure per class
for cls in range(10):

    clahe_img = equalized_clahe[cls]
    best_name = best_filters[cls]
    best_img = filter_dict[best_name][cls]

    sobel_clahe = sobel_edges(clahe_img)
    sobel_best = sobel_edges(best_img)

    fig, axes = plt.subplots(1, 4, figsize=(20, 5))

    axes[0].imshow(clahe_img, cmap="gray")
    axes[0].set_title(f"Class {cls} — {class_names[cls]}\nCLAHE")
    axes[0].axis("off")

    axes[1].imshow(sobel_clahe, cmap="gray")
    axes[1].set_title("Sobel(CLAHE)")
    axes[1].axis("off")

    axes[2].imshow(best_img, cmap="gray")
    axes[2].set_title(f"{best_name}")
    axes[2].axis("off")

    axes[3].imshow(sobel_best, cmap="gray")
    axes[3].set_title(f"Sobel({best_name})")
    axes[3].axis("off")

    plt.tight_layout()
    plt.show()

"""### Canny Edge Detector"""

# -------------------------------------------------------------
# STEP X — CANNY (FIXED + ADAPTIVE) FOR CLAHE AND BEST FILTER
# -------------------------------------------------------------


# ---- CANNY HELPERS --------------------------------------------------------

def canny_fixed(img, low=50, high=150):
    return cv2.Canny(img, low, high)

def canny_adaptive(img):
    median = np.median(img)
    low = int(max(0, 0.66 * median))
    high = int(min(255, 1.33 * median))
    return cv2.Canny(img, low, high)


# ---- BEST FILTERS PER CLASS -----------------------------------------------

best_filters = {
    0: "Bilateral_Light",
    1: "Unsharp_Light",
    2: "Median_3x3",
    3: "Unsharp_Light",
    4: "Median_3x3",
    5: "Unsharp_Light",
    6: "Bilateral_Light",
    7: "Unsharp_Light",
    8: "Unsharp_Light",
    9: "Bilateral_Light",
}

filter_dict = {
    "Gauss_3x3": gauss_3,
    "Gauss_5x5": gauss_5,
    "Gauss_9x9": gauss_9,
    "Median_3x3": median_3,
    "Median_5x5": median_5,
    "Median_7x7": median_7,
    "Bilateral_Light": bilat_light,
    "Bilateral_Medium": bilat_med,
    "Bilateral_Strong": bilat_strong,
    "Unsharp_Light": unsharp_light,
    "Unsharp_Medium": unsharp_medium,
    "Unsharp_Strong": unsharp_strong,
}

# ---- MAIN LOOP ------------------------------------------------------------

for cls in range(10):

    clahe_img = equalized_clahe[cls]
    best_name = best_filters[cls]
    best_img = filter_dict[best_name][cls]

    # Canny outputs
    canny_fixed_clahe    = canny_fixed(clahe_img)
    canny_adaptive_clahe = canny_adaptive(clahe_img)

    canny_fixed_best     = canny_fixed(best_img)
    canny_adaptive_best  = canny_adaptive(best_img)

    # Plotting (6 images per class)
    fig, axes = plt.subplots(1, 6, figsize=(28, 5))

    axes[0].imshow(clahe_img, cmap="gray")
    axes[0].set_title(f"Class {cls}: {class_names[cls]}\nCLAHE")
    axes[0].axis("off")

    axes[1].imshow(canny_fixed_clahe, cmap="gray")
    axes[1].set_title("Canny Fixed\n(CLAHE)")
    axes[1].axis("off")

    axes[2].imshow(canny_adaptive_clahe, cmap="gray")
    axes[2].set_title("Canny Adaptive\n(CLAHE)")
    axes[2].axis("off")

    axes[3].imshow(best_img, cmap="gray")
    axes[3].set_title(f"{best_name}")
    axes[3].axis("off")

    axes[4].imshow(canny_fixed_best, cmap="gray")
    axes[4].set_title(f"Canny Fixed\n({best_name})")
    axes[4].axis("off")

    axes[5].imshow(canny_adaptive_best, cmap="gray")
    axes[5].set_title(f"Canny Adaptive\n({best_name})")
    axes[5].axis("off")

    plt.tight_layout()
    plt.show()

"""##Connected Components"""

#store the best mask
canny_best_adaptive = {}

for cls in range(10):
    best_name = best_filters[cls]
    best_img  = filter_dict[best_name][cls]

    edges = canny_adaptive(best_img)
    canny_best_adaptive[cls] = edges

#connected components

cc_labels  = {}
cc_stats   = {}
cc_centers = {}
cc_counts  = {}

for cls in range(10):
    edges = canny_best_adaptive[cls]

    edges_bin = (edges > 0).astype(np.uint8) * 255

    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
        edges_bin, connectivity=8
    )

    cc_labels[cls]  = labels
    cc_stats[cls]   = stats
    cc_centers[cls] = centroids
    cc_counts[cls]  = num_labels - 1  # excluding background

    #visualize

for cls in range(10):
    best_name = best_filters[cls]
    best_img  = filter_dict[best_name][cls]

    edges = canny_best_adaptive[cls]
    edges_bin = (edges > 0).astype(np.uint8) * 255

    labels = cc_labels[cls]

    max_label = int(np.max(labels)) if int(np.max(labels)) > 0 else 1

    label_hue = np.uint8(179 * labels / max_label)
    blank_ch = 255 * np.ones_like(label_hue, dtype=np.uint8)
    labeled_hsv = cv2.merge([label_hue, blank_ch, blank_ch])

    # Background = black
    labeled_hsv[label_hue == 0] = 0

    labeled_bgr = cv2.cvtColor(labeled_hsv, cv2.COLOR_HSV2BGR)
    labeled_rgb = cv2.cvtColor(labeled_bgr, cv2.COLOR_BGR2RGB)

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    axes[0].imshow(best_img, cmap="gray")
    axes[0].set_title(f"Class {cls}: {class_names[cls]}\nBest Filter: {best_name}")
    axes[0].axis("off")

    axes[1].imshow(edges_bin, cmap="gray")
    axes[1].set_title("Canny (Adaptive) on Best Filter")
    axes[1].axis("off")

    axes[2].imshow(labeled_rgb)
    axes[2].set_title("Connected Components")
    axes[2].axis("off")

    plt.tight_layout()
    plt.show()

"""##Highlighting the Fracture - no thresholding"""

fracture_candidates = {}

for cls in range(10):

    # --- Use MASKED edges ---
    edges = canny_best_adaptive[cls]

    # Ensure binary
    edges_bin = (edges > 0).astype(np.uint8) * 255

    h, w = edges_bin.shape

    # Connected components ON THE MASKED EDGES
    num_labels, labels, stats, centers = cv2.connectedComponentsWithStats(
        edges_bin, connectivity=8
    )

    best_label = None
    best_score = -1
    best_aspect = None

    for label_id in range(1, num_labels):  # skip background

        area = stats[label_id, cv2.CC_STAT_AREA]
        x    = stats[label_id, cv2.CC_STAT_LEFT]
        y    = stats[label_id, cv2.CC_STAT_TOP]
        bw   = stats[label_id, cv2.CC_STAT_WIDTH]
        bh   = stats[label_id, cv2.CC_STAT_HEIGHT]

        # --- Reject tiny or huge regions ---
        if area < 30 or area > 4000:
            continue

        # --- Reject border-touching components ---
        if x == 0 or y == 0 or (x + bw) >= w - 1 or (y + bh) >= h - 1:
            continue

        # --- Shape constraint: long & thin ---
        aspect_ratio = max(bw, bh) / (min(bw, bh) + 1e-6)
        if aspect_ratio < 2.5:
            continue

        # --- Score ---
        score = area * aspect_ratio

        if score > best_score:
            best_score = score
            best_label = label_id
            best_aspect = aspect_ratio

    # ----------------------------
    # Overlay result
    # ----------------------------
    best_name = best_filters[cls]
    base_img  = filter_dict[best_name][cls]
    overlay   = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)

    if best_label is not None:
        mask = (labels == best_label)
        overlay[mask] = [255, 0, 0]  # red

        cx, cy = centers[best_label]
        fracture_candidates[cls] = {
            "label": int(best_label),
            "area": int(stats[best_label, cv2.CC_STAT_AREA]),
            "aspect_ratio": float(best_aspect),
            "center": (float(cx), float(cy)),
        }
    else:
        fracture_candidates[cls] = None

    # ----------------------------
    # Visualization
    # ----------------------------
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    axes[0].imshow(base_img, cmap="gray")
    axes[0].set_title(
        f"Class {cls}: {class_names[cls]}\nBest Filter: {best_name}"
    )
    axes[0].axis("off")

    axes[1].imshow(edges_bin, cmap="gray")
    axes[1].set_title("Canny")
    axes[1].axis("off")

    axes[2].imshow(overlay)
    axes[2].set_title(
        "Fracture Candidate (Red)" if best_label is not None else "No Candidate Detected"
    )
    axes[2].axis("off")

    plt.tight_layout()
    plt.show()

"""##Thresholding"""

#
bone_masks = {}
kernel = np.ones((3, 3), np.uint8)

for cls in range(10):
    img = equalized_clahe[cls]           # CLAHE image for this class
    img = img.astype(np.uint8)

    # Otsu threshold
    _, th = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Make sure bone is white (255)
    mean_white = img[th == 255].mean() if np.any(th == 255) else 0
    mean_black = img[th == 0].mean() if np.any(th == 0) else 0
    if mean_white < mean_black:
        th = cv2.bitwise_not(th)

    # Morphological clean up
    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)
    th = cv2.morphologyEx(th, cv2.MORPH_OPEN,  kernel, iterations=1)

    # Remove a border margin so we don't pick the X-ray frame as "bone"
    h, w = th.shape
    border = int(0.05 * min(h, w))  # 5% margin
    th[:border, :] = 0
    th[-border:, :] = 0
    th[:, :border] = 0
    th[:, -border:] = 0

    bone_masks[cls] = th

print("Bone masks computed and border suppressed.")

to_show = [0, 3, 4, 8]  # pick a few classes that look interesting
plt.figure(figsize=(10, 8))
for i, cls in enumerate(to_show):
    plt.subplot(len(to_show), 2, 2*i + 1)
    plt.imshow(equalized_clahe[cls], cmap="gray")
    plt.title(f"CLAHE - Class {cls} {class_names[cls]}")
    plt.axis("off")

    plt.subplot(len(to_show), 2, 2*i + 2)
    plt.imshow(bone_masks[cls], cmap="gray")
    plt.title("Otsu Bone Mask")
    plt.axis("off")

plt.tight_layout()
plt.show()

"""##Edge detection with bone mask to avoid x-ray photo edges"""

canny_best_masked = {}

for cls in range(10):
    best_name = best_filters[cls]
    best_img  = filter_dict[best_name][cls]

    edges = canny_adaptive(best_img)            # your existing helper
    mask  = bone_masks[cls]                    # Otsu bone mask
    edges_masked = cv2.bitwise_and(edges, edges, mask=mask)

    canny_best_masked[cls] = edges_masked

print("Masked edge maps stored in canny_best_masked[cls].")

to_show = [0, 3, 4, 8]
plt.figure(figsize=(12, 3 * len(to_show)))

for i, cls in enumerate(to_show):
    best_name = best_filters[cls]
    best_img  = filter_dict[best_name][cls]

    plt.subplot(len(to_show), 3, 3*i + 1)
    plt.imshow(best_img, cmap="gray")
    plt.title(f"Best Filter: {best_name}\nClass {cls} {class_names[cls]}")
    plt.axis("off")

    plt.subplot(len(to_show), 3, 3*i + 2)
    plt.imshow(bone_masks[cls], cmap="gray")
    plt.title("Bone Mask (Otsu)")
    plt.axis("off")

    plt.subplot(len(to_show), 3, 3*i + 3)
    plt.imshow(canny_best_masked[cls], cmap="gray")
    plt.title("Canny ∧ Bone Mask")
    plt.axis("off")

plt.tight_layout()
plt.show()

"""##Connected components on the new canny edge detection"""

cc_labels = {}
cc_stats  = {}
cc_centers = {}

for cls in range(10):
    edges = canny_best_masked[cls]

    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
        edges, connectivity=8
    )

    cc_labels[cls]  = labels
    cc_stats[cls]   = stats
    cc_centers[cls] = centroids

    print(f"Class {cls} ({class_names[cls]}): {num_labels-1} components (inside bone)")

# Example visual per class
for cls in [0, 3, 4, 8]:  # or range(10)
    edges = canny_best_masked[cls]
    labels = cc_labels[cls]

    max_label = np.max(labels) if np.max(labels) > 0 else 1
    label_hue = np.uint8(179 * labels / max_label)
    blank_ch = 255 * np.ones_like(label_hue)
    labeled_hsv = cv2.merge([label_hue, blank_ch, blank_ch])
    labeled_hsv[label_hue == 0] = 0

    labeled_bgr = cv2.cvtColor(labeled_hsv, cv2.COLOR_HSV2BGR)
    labeled_rgb = cv2.cvtColor(labeled_bgr, cv2.COLOR_BGR2RGB)

    best_name = best_filters[cls]
    best_img  = filter_dict[best_name][cls]

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    axes[0].imshow(best_img, cmap="gray")
    axes[0].set_title(f"Best Filter: {best_name}\nClass {cls} {class_names[cls]}")
    axes[0].axis("off")

    axes[1].imshow(edges, cmap="gray")
    axes[1].set_title("Canny ∧ Bone Mask")
    axes[1].axis("off")

    axes[2].imshow(labeled_rgb)
    axes[2].set_title("Connected Components (Inside Bone)")
    axes[2].axis("off")

    plt.tight_layout()
    plt.show()

"""##Highlight fractures in red"""

fracture_candidates = {}

for cls in range(10):

    edges   = canny_best_masked[cls]     # Canny after bone mask
    labels  = cc_labels[cls]
    stats   = cc_stats[cls]
    centers = cc_centers[cls]

    h, w = edges.shape

    best_label = None
    best_score = -1

    for label_id in range(1, stats.shape[0]):  # skip background

        area = stats[label_id, cv2.CC_STAT_AREA]
        x    = stats[label_id, cv2.CC_STAT_LEFT]
        y    = stats[label_id, cv2.CC_STAT_TOP]
        bw   = stats[label_id, cv2.CC_STAT_WIDTH]
        bh   = stats[label_id, cv2.CC_STAT_HEIGHT]

        # --- Reject tiny or huge regions ---
        if area < 30 or area > 4000:
            continue

        # --- Reject border-touching components (frame / artifacts) ---
        if x == 0 or y == 0 or (x + bw) >= w-1 or (y + bh) >= h-1:
            continue

        # --- Shape constraint: fractures are long & thin ---
        aspect_ratio = max(bw, bh) / (min(bw, bh) + 1e-6)
        if aspect_ratio < 2.5:
            continue

        # --- Score: favor elongated, mid-sized components ---
        score = area * aspect_ratio

        if score > best_score:
            best_score = score
            best_label = label_id

    # ----------------------------
    # Overlay result
    # ----------------------------
    best_name = best_filters[cls]
    base_img  = filter_dict[best_name][cls]
    overlay   = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)

    if best_label is not None:
        mask = (labels == best_label)
        overlay[mask] = [255, 0, 0]  # red overlay

        cx, cy = centers[best_label]
        fracture_candidates[cls] = {
            "label": best_label,
            "area": int(stats[best_label, cv2.CC_STAT_AREA]),
            "aspect_ratio": float(aspect_ratio),
            "center": (float(cx), float(cy))
        }
    else:
        fracture_candidates[cls] = None

    # ----------------------------
    # Visualization
    # ----------------------------
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    axes[0].imshow(base_img, cmap="gray")
    axes[0].set_title(
        f"Class {cls}: {class_names[cls]}\nBest Filter: {best_name}"
    )
    axes[0].axis("off")

    axes[1].imshow(edges, cmap="gray")
    axes[1].set_title("Canny ∧ Otsu Bone Mask")
    axes[1].axis("off")

    axes[2].imshow(overlay)
    if best_label is not None:
        axes[2].set_title("Fracture Candidate (Red)")
    else:
        axes[2].set_title("No Candidate Detected")
    axes[2].axis("off")

    plt.tight_layout()
    plt.show()